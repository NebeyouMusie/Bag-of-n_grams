{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omtdh4pSsWaM"
      },
      "source": [
        "# Bag of n_grams\n",
        "- Fake news refers to misinformation or disinformation in the country which is spread through word of mouth and more recently through digital communication such as What's app messages, social media posts, etc.\n",
        "\n",
        "- Fake news spreads faster than Real news and creates problems and fear among groups and in society.\n",
        "\n",
        "- We are going to address these problems using classical NLP techniques and going to classify whether a given message/ text is Real or Fake Message.\n",
        "\n",
        "- You will use a Bag of n-grams to pre-process the text and apply different classification algorithms.\n",
        "\n",
        "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SbYYS0q6EhS"
      },
      "source": [
        "## About Data: Fake News Detection\n",
        "- Credits: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
        "\n",
        "  - This data consists of two columns. - Text - label\n",
        "\n",
        "  - Text is the statements or messages regarding a particular event/situation.\n",
        "\n",
        "  - label feature tells whether the given Text is Fake or Real.\n",
        "\n",
        "  - As there are only 2 classes, this problem comes under the Binary Classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGJEFKFqoF5O"
      },
      "outputs": [],
      "source": [
        "# import pandas library\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "W3MSwrKi6O9G",
        "outputId": "8d0b29be-d93a-4541-8fcf-94bfbd7c0698"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
              "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
              "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
              "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
              "\n",
              "                                                text subject  \\\n",
              "0  Donald Trump just couldn t wish all Americans ...    News   \n",
              "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
              "2  On Friday, it was revealed that former Milwauk...    News   \n",
              "3  On Christmas day, Donald Trump announced that ...    News   \n",
              "4  Pope Francis used his annual Christmas Day mes...    News   \n",
              "\n",
              "                date label  \n",
              "0  December 31, 2017  Fake  \n",
              "1  December 31, 2017  Fake  \n",
              "2  December 30, 2017  Fake  \n",
              "3  December 29, 2017  Fake  \n",
              "4  December 25, 2017  Fake  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the fake data\n",
        "fake_data = pd.read_csv('./Bag-of-n_grams/Fake.csv')\n",
        "\n",
        "# add a column called label\n",
        "fake_data['label'] = 'Fake'\n",
        "\n",
        "# print 5 rows\n",
        "fake_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "eXq3G_Ac6iqO",
        "outputId": "694cfc73-4872-4463-be44-f0aaa27ed190"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
              "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U.S. military to accept transgender recruits o...</td>\n",
              "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
              "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
              "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
              "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  As U.S. budget fight looms, Republicans flip t...   \n",
              "1  U.S. military to accept transgender recruits o...   \n",
              "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
              "3  FBI Russia probe helped by Australian diplomat...   \n",
              "4  Trump wants Postal Service to charge 'much mor...   \n",
              "\n",
              "                                                text       subject  \\\n",
              "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
              "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
              "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
              "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
              "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
              "\n",
              "                 date label  \n",
              "0  December 31, 2017   True  \n",
              "1  December 29, 2017   True  \n",
              "2  December 31, 2017   True  \n",
              "3  December 30, 2017   True  \n",
              "4  December 29, 2017   True  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load true data\n",
        "true_data = pd.read_csv('./Bag-of-n_grams/True.csv')\n",
        "\n",
        "# add a column called label\n",
        "true_data['label'] = 'True'\n",
        "\n",
        "# print 5 rows\n",
        "true_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mQMmYaeh60tF",
        "outputId": "2d92e135-ac26-467a-f064-0612b5e7adfa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label\n",
              "0  Donald Trump just couldn t wish all Americans ...  Fake\n",
              "1  House Intelligence Committee Chairman Devin Nu...  Fake\n",
              "2  On Friday, it was revealed that former Milwauk...  Fake\n",
              "3  On Christmas day, Donald Trump announced that ...  Fake\n",
              "4  Pope Francis used his annual Christmas Day mes...  Fake"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# concatenate fake_data and true_data into one dataframe\n",
        "data = pd.concat([fake_data, true_data], axis=0)\n",
        "data = data[['text', 'label']]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxrE6rKH9115",
        "outputId": "80c6ff69-fd5f-478e-80c4-2cc9ac1f02bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "Fake    23481\n",
              "True    21417\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check distribution of labels\n",
        "data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YXAXvAP7-XyC",
        "outputId": "a688e48f-ba7e-42b7-8337-f3f698bd7cc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>Fake</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text label  label_num\n",
              "0  Donald Trump just couldn t wish all Americans ...  Fake          0\n",
              "1  House Intelligence Committee Chairman Devin Nu...  Fake          0\n",
              "2  On Friday, it was revealed that former Milwauk...  Fake          0\n",
              "3  On Christmas day, Donald Trump announced that ...  Fake          0\n",
              "4  Pope Francis used his annual Christmas Day mes...  Fake          0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add the new column \"label_num\" which gives a unique number to each of these labels\n",
        "data['label_num'] = data['label'].map({'Fake': 0, 'True': 1})\n",
        "\n",
        "# check the results with top 5 rows\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5WWsDcE-xZM"
      },
      "source": [
        "## Modelling without Pre-processing Text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V-ffvHaC-zVJ"
      },
      "outputs": [],
      "source": [
        "# import train-test-split from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# assign feature and target variables\n",
        "X = data['text']\n",
        "y = data['label_num']\n",
        "\n",
        "# Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgYRh0mXABnA",
        "outputId": "f99f3efc-a84d-4550-a929-e55a8ee672ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape (35918,)\n",
            "X_test shape (8980,)\n"
          ]
        }
      ],
      "source": [
        "# print the shapes of X_train and X_test\n",
        "print('X_train shape', X_train.shape)\n",
        "print('X_test shape', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCcB3-YZAQtq"
      },
      "source": [
        "## Attempt 1 :\n",
        "\n",
        "- using sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "Note:\n",
        "\n",
        "  - using CountVectorizer with unigram, bigram, and trigrams.\n",
        "  - use KNN as the classifier with n_neighbors of 10 and metric as 'euclidean' distance.\n",
        "  - print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHd4PtCeAWxZ",
        "outputId": "7eb854d6-e5c8-4237-afe0-3b3975601ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79      4696\n",
            "           1       0.78      0.71      0.75      4284\n",
            "\n",
            "    accuracy                           0.77      8980\n",
            "   macro avg       0.77      0.77      0.77      8980\n",
            "weighted avg       0.77      0.77      0.77      8980\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#1. create a pipeline object\n",
        "clf = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=10, metric='euclidean'))\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh7vAcGHCac0"
      },
      "source": [
        "## Attempt 2 :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "Note:\n",
        "\n",
        "  - using CountVectorizer with unigram, bigram, and trigrams.\n",
        "  - use KNN as the classifier with n_neighbors of 10 and metric as 'cosine' distance.\n",
        "  - print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQn1P9q3DFs4",
        "outputId": "7e7f4bdb-0522-44a0-c359-5064ce497e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.98      0.78      4696\n",
            "           1       0.95      0.41      0.57      4284\n",
            "\n",
            "    accuracy                           0.71      8980\n",
            "   macro avg       0.80      0.69      0.67      8980\n",
            "weighted avg       0.79      0.71      0.68      8980\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1. create a pipeline object\n",
        "clf = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),\n",
        "    ('knnc', KNeighborsClassifier(n_neighbors=10, metric='cosine'))\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ROfoe_ADH2a"
      },
      "source": [
        "## Attempt 3 :\n",
        "\n",
        "- using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "Note:\n",
        "\n",
        "  - using CountVectorizer with only trigrams.\n",
        "  - use RandomForest as the classifier.\n",
        "  - print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import random forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "clf = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(3, 3))),\n",
        "    ('random_forest', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classification_report(y_test ,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MXAHv6XEJ8h"
      },
      "source": [
        "## Attempt 4 :\n",
        "\n",
        "- using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "Note:\n",
        "\n",
        "  - using CountVectorizer with both unigram and bigrams.\n",
        "  - use Multinomial Naive Bayes as the classifier with an alpha value of 0.75.\n",
        "  - print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpdzUmKyIznh"
      },
      "outputs": [],
      "source": [
        "# import MultinomialNB\n",
        "from sklearn.naive_bayes import MultiNomialNB\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "clf = Pipeline([\n",
        "      ('vectoizer', CountVectorizer(ngram_range=(1, 2))),\n",
        "      ('mb', MultinomialNB(alpha=0.75))\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "clf.fit(X_test, y_test)\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "print(classifiaction_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use text pre-processing to remove stop words, punctuations and apply lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import spacy\n",
        "\n",
        "# load english language model and create nlp object\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "# define the preprocess function\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize\n",
        "    doc = nlp(text)\n",
        "    filtered_text = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_text.append(token.lemma_)\n",
        "    \n",
        "    return ' '.join(filtered_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a new column \"preprocessed_txt\" and use the utility function above to get the clean data\n",
        "data['preprocessed_txt'] = data['text'].apply(preprocess)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a model with pre processed text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data['prprocessed_text']\n",
        "y= data['label_num']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Let's check the scores with our best model till now\n",
        "\n",
        "- Random Forest\n",
        "### Attempt1 :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "Note:\n",
        "    - using CountVectorizer with only trigrams.\n",
        "    - use RandomForest as the classifier.\n",
        "    - print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "clf = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(3, 3))),\n",
        "    ('random_forest', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attempt2 :\n",
        "\n",
        "- using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "Note:\n",
        "    - using CountVectorizer with unigram, Bigram, and trigrams.\n",
        "    - use RandomForest as the classifier.\n",
        "    - print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "clf = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(ngram_range=(1, 3))),\n",
        "    ('random_forest', RandomForestClassifier())\n",
        "])\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "#4. print the classfication report\n",
        "classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the confusion matrix for the best model using heatmap\n",
        "\n",
        "# import confusion_matrix from sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# import matplotlib na d seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm\n",
        "\n",
        "plt.figure=(figsize= (10, 7))\n",
        "sns.heatmpa(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Observations\n",
        "- As machine learning algorithms do not work on text data directly, we need to convert them into numeric vectors and feed that into models while training.\n",
        "\n",
        "- In this process, we convert text into a very high dimensional numeric vector using the technique of Bag of words and we use sklearn CountVectorizer for this.\n",
        "\n",
        "### Without Pre-Processing Data\n",
        "\n",
        "- From the above in most of the cases, we can see that when we have the count vectorizer above trigrams or at trigrams, the performance keeps degrading. The major possible reason for this as the ngram_range keeps increasing, the number of dimensions/features (possible combination of words) also increases enormously and models have the risk of overfitting and resulting in terrible performance.\n",
        "\n",
        "- For this reason, models like KNN failed terribly when performed with trigrams and using the euclidean distance. K-Nearest Neighbours(KNN) doesn't work well with high-dimensional data because, with a large number of dimensions, it becomes difficult for the algorithm to calculate the distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of the model. It performed well for class 1 and had terrible results for Class 0.\n",
        "\n",
        "- Both recall and F1 scores increase better when trained with the same KNN model but with cosine distance as cosine distance does not get influenced by the number of dimensions as it uses the angle better the two text vectors to calculate the similarity.\n",
        "\n",
        "- With respect to Naive and RandomForest models, both performed really well, and random forest with trigrams has a better edge on the recall metric.\n",
        "\n",
        "- As Random Forest uses Bootstrapping(row and column Sampling) with many decision trees and overcomes the high variance and overfitting of high dimensional data and also uses feature importance of words for better classifying the categories.\n",
        "\n",
        "- The easy calculation of probabilities for the words in the corpus(Bag of words) and storing them in a contingency table is the major reason for the Multinomial NaiveBayes to be a text classification friendly algorithm.\n",
        "\n",
        "### With Pre-Processing Data\n",
        "\n",
        "- Have trained the best model RandomForest on the pre-processed data, but RandomForest with trigrams fails to produce the same results here.\n",
        "\n",
        "- But the same randomForest with Unigram to Trigram features helps to produce very amazing results and is tops in the entire list with very good F1 scores and Recall scores.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
